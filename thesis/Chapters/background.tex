% !TeX spellcheck = en_US
% Chapter Template

\chapter{Background and problem statement} % Main chapter title

\label{chap:background} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter \ref*{chap:background}. \emph{Background and problem statement}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

\section{Application under study}
\acf{OT} is an open-source simulation platform developed by the university of Applied Sciences in Frankfurt, Germany. It covers features like computer aided design and meshing and is also a physics simulation (having solvers for Finite Integration and PHREEC). The projects can be administered by a user and group management (see~\autoref{fig:ot-project}). Furthermore, all changes on a project are version-controlled. The application is designed in a way, that only a local thin-client needs to run on the users computer. After entering the login credentials (see~\autoref{fig:ot-login}), the client securely connects to a centralized service platform where the computation is made. The results and even the \ac{UI} information is sent back to the client application.  This has the benefit, that also underpowered computers can run the application.
Further details about the network protocol are explained later in this section.

\begin{figure}[ht]
	\centering
	\fbox{\includegraphics[width=.9\textwidth]{Figures/ot-project.png}}
	\caption{The \ac{OT} project overview.}
	\label{fig:ot-project}
\end{figure}

\begin{figure}[ht]
	\centering
	\fbox{\includegraphics[width=.9\textwidth]{Figures/ot-login.png}}
	\caption{The \ac{OT} login screen.}
	\label{fig:ot-login}
\end{figure}

\autoref{fig:ot-model} shows the application itself with a loaded project and a simple geometric model.
\begin{figure}[ht]
	\centering
	\fbox{\includegraphics[width=.9\textwidth]{Figures/ot-model.png}}
	\caption{An opened project inside \ac{OT} with a few created geometric models and a boolean operation.}
	\label{fig:ot-model}
\end{figure}

The development team consists of a small core team and several student groups during the semester.


\section{Baseline architecture}
\label{chap:background.baseline_architecture}
The current system design consists of multiple levels. It is a multi-process application based on the programming languages C++ and Rust. The source code is mainly aligned to be built on Microsoft \ac{Windows}. A port to Unix based systems is currently in work. Therefore parts of the code base are aligned for multiple system architectures already, but the application is not yet able to be compiled for Linux.

Each microservice of the application is included dynamically and linked as a \ac{DLL} file. For starting the microservice environment, a central executable (\enquote{open\_\ twin.exe}) is started with the corresponding arguments for the services (like the server's binding address, port numbers, and passwords) (see~\autoref{lst:ot-command}) and the path to the \ac{DLL} file itself. The \ac{UI} front end, which is started by the user directly, is compiled in its own executable (\enquote{uiFrontend.exe}).

\begin{lstlisting}[language=sh, caption={Command line of Open Twin Service start}, label=lst:ot-command]
open_twin.exe GlobalSessionService.dll \
  "0" "127.0.0.1:8091" "tls@127.0.0.1:27017" "127.0.0.1:8092"
\end{lstlisting}

For conveniently running the services with all their necessary arguments, batch files are provided that read environment variables and convert them into runtime arguments for the service executable. Therefore, if the services are started locally, the user runs a batch file that sets up the environment for the network binding details, path to certificates and encrypted database credentials.

The system consists of the following microservices that are permanently accessible: \acf{GSS}, \acf{AUTH} and the database. The database is running on MongoDB\footnote{MongoDB:~https://www.mongodb.com/}. Another Service is the \acf{LSS} that spawns the so called compute services. Those are services for running the actual computation after opening a project that can dynamically spawn and exit. A partial list of compute services and their corresponding tasks can be found in \autoref{tbl:ot-compute-services}.
Each service runs in its own \ac{OS} process.

\begin{table}[h!]
	\centering
	\begin{tabular}{|l | p{.65\textwidth}|} 
		\hline
		\bfseries Name & \bfseries Task  \rule{-5pt}{2.6ex} \\
		\hline \rule{-3pt}{3ex}
		CartesianMeshService & If demanded, it converts a continuous geometry into a discrete Cartesian mesh. \\
		FITTDService & If demanded, it runs a solver algorithm for transle electromagnetic simulation based on the finite integration technique (FIT).\\
		KrigingService & If demanded, it runs a kriging interpolation of result data. \\ 
		LoggerService & A background service, that accepts logging messages from other services. \\ 
		ModelingService & Performs calculations for the creation, modeling and boolean combination of geometric data. \\ 
		PHREECService & If demanded, it runs simulation based on PHREEC. \\ 
		TetMeshService & If demanded, it meshes a form with an tetrahedral mesh.  \\ 
		VisualizationService & Runs the graphical calculations for displaying the geometric and data based results on the \ac{UI}.\\ 
		[1ex] 
		\hline
	\end{tabular}
	\caption{List of compute services and their corresponding tasks.}
	\label{tbl:ot-compute-services}
\end{table}

The Visualization Service requires features from version 2.0 of the graphics library OpenGL\footnote{OpenGL: https://opengl.org/}. Systems where no graphics card is installed or systems that run a server \ac{OS} do not have OpenGL 2.0 available. For these environments the \ac{DLL} file \enquote{opengl32sw.dll} in the installation directory can be renamed to \enquote{opengl32.dll}. This enables software rendering and allows system to run \ac{OT} that do not meet this requirement.

As shown in \autoref{fig:ot-network-communication-diagram}, the services can be separated by their network space on multiple levels. Not all services require a public available network address.
While \ac{GSS}, \ac{AUTH} and database are globally accessible via a fixed network address, the \ac{LSS} can theoretically run on a dedicated host and is only communicated to other parties after it has registered itself to the \ac{GSS}. The services, spawned by \ac{LSS}, do not require a public address space either. All communication between the \ac{UI} front end and the compute services is achieved via a relay service and a WebSocket\cite{Fette.2011} communication channel.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{Figures/opentwin-network-communication-diagram.pdf}
	\caption{Communication overview and service organization for \ac{OT} main services. In 1.1 the \ac{LSS} registers at \ac{GSS}. As soon as the \ac{UI} front end connects to the \ac{GSS}~(2.1), service information is exchanged~(2.2) and the user is authenticated~(2.3). As a consequence, the \ac{GSS} creates a new session and tells the \ac{LSS} to spawn new compute services. From now on the \ac{UI} front end communicates directly with the Compute services via the Relay Service over a WebSocket connection.}
	\label{fig:ot-network-communication-diagram}
\end{figure}


The whole process of the \ac{LSS} registration and connection of the \ac{UI} front end to the compute services is depicted in \autoref{fig:ot-network-communication-sequence}.
Once started, the user can login. In order to connect to the database, the following steps are performed:
\begin{enumerate}
\item The \ac{UI} front end requests further service information from the publicly available \ac{GSS}. The address for this service is provided by the user. The \ac{GSS} responds with \acp{URL} to the database and the \ac{AUTH}.
\item The \ac{UI} front end connects to the \ac{AUTH} using the authentication information provided by the user.
\item If the \ac{AUTH} replies with a positive authentication, the \ac{UI} front end connects to the database and lists the projects.
\item Once a project is opened or created, the \ac{UI} front end requests a new session from the \ac{GSS}. The \ac{GSS} replies with the connection \acp{URL} of the \ac{LSS}. The \ac{LSS} has been registered to the \ac{GSS} during its initialization.
\item The \ac{UI} front end then connects to the \ac{LSS} and requests a new session. As a result, the \ac{LSS} spawns new application service processes and replies with the respective service \acp{URL}.
\item From now on, the \ac{UI} front end communicates with the application services via the Relay service over a WebSocket.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.99\textwidth]{Figures/opentwin-network-communication-sequence.pdf}
	\caption{Service initialization of \ac{OT} processes. In the beginning, the main services \ac{GSS}, \ac{AUTH} and an optional \ac{LSS} are initialized. While the \ac{GSS} checks the reachability of \ac{AUTH}, the \ac{LSS} registers itself at the \ac{GSS}. After starting the \ac{UI} front end, the service information is requested from a \ac{GSS} and the user is authenticated. Afterwards, the project list for the authenticated user is displayed. After opening a project, the \ac{UI} front end connects to the \ac{LSS} and requests a new session. As consequence, the \ac{LSS} spawns the compute services and connects them to the \ac{UI} front end via a Relay Service. (Ping messages are omitted.)}
	\label{fig:ot-network-communication-sequence}
\end{figure}

%The traffic between services is encrypted using \ac{mTLS} technology. While regular \ac{TLS} ensures the authenticity of the server by using Certificates and the chain of trust, it does not verify the identity of the client. This is the benefit of \ac{mTLS}. In \ac{mTLS}, both sides, client and server has to verify their identity by providing a certificate inherited from a common root authority.


\section{Network traffic encryption}

Each service of \ac{OT} offers two different channels for secure communication between services. One channel supports traditional one-way \ac{TLS}, while the other uses bidirectional \ac{mTLS}. The one-way \ac{TLS} channel is mostly used for checking the general health state of a service, while the two-way \ac{mTLS} is used for relevant application based communication.
In this section both encryption methods are briefly presented.

\subsection{Transport Layer Security}
\ac{TLS} is an cryptography extension mainly designed for providing security over \ac{HTTP}. The main goals of cryptography are confidentiality, integrity and authenticity between two communicating parties. This means, the communication on a network is kept secret between the two endpoints (Confidentiality), messages are not subject of manipulation (Integrity), and message exchanges are only allowed between authorized and trusted individuals (Authenticity). \ac{TLS} ensures the three traits by using certificates.

A simplified handshake of the \ac{TLS} protocol is depicted in \autoref{fig:tls-protocol}.
After sending the certificate from server to the client, the client validates the certificate based on the chain of trust. This means, it checks if the certificate was issued by a trusted root authority (so called \ac{CA}). Only if the authenticity of the server is ensured, the encryption key is exchanged in order to start an encrypted communication.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{Figures/tls.pdf}
	\caption{Simplified visualization of the \ac{TLS} handshake\cite{Rescorla.2018}. After initialization of the handshake (1,2), the server sends its certificate (3) and finishes with a message \enquote{Hello Done} (4). The client then validates the certificate and compares it against the chain of trust. Afterwards, the key exchange starts (5,6) to ensure an encrypted communication.}
	\label{fig:tls-protocol}
\end{figure}


\subsection{Mutual authentication}
The mutual authentication is adding another step to the one-way authentication. The application of it is used in \ac{mTLS} as extension of the classic \ac{TLS} protocol\cite{Rescorla.2018, HugoKrawczyk.2016}. Instead of just sending the server's certificate to the client, the client also sends a certificate to the server. Therefore, not only the authenticity of the server is ensured, but also of the client.

As can be seen in \autoref{fig:mtls-protocol}, compared to the \ac{TLS} handshake, the \ac{mTLS} handshake involves additional messages 5 and 6 for sending and validating the client's certificate.
Unlike with the server certificate, the client certificate is not validated against a publicly available root authority\cite{Cloudflare.20230309, Rescorla.2018}. Instead, the server acts as root authority, creates the client certificate and ships it with the application\cite{Cloudflare.20230309}.


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{Figures/mtls.pdf}
	\caption{Simplified visualization of the \ac{mTLS} handshake\cite{Cloudflare.20230309, Rescorla.2018}. After initialization of the handshake (1,2), the server sends its certificate (3) and finishes with a message \enquote{Hello Done} (4). The client then validates the certificate and compares it against the locally stored root authority. Afterwards, the client sends its certificate to the server (5). The server validates the client certificate against its local root authority and grants access to the service (6). Afterwards, the key exchange starts (7,8) to ensure an encrypted communication.}
	\label{fig:mtls-protocol}
\end{figure}


\subsection{Certificate creation}
For creation of certificates in the application landscape of \ac{OT}, CloudFlare's public key infrastructure toolkit \enquote{cfssl}\footnote{cfssl: https://cfssl.org/ or https://github.com/cloudflare/cfssl} is used.
For generating certificates with the toolkit, it is fed with a JSON file with subject information for the \ac{CSR}.

It contains information about the issuer, as well as the name and cryptography algorithm of the certificate.
Additionally, the client and server certificate that derive from the root \ac{CA} contain information for whitelisted hosts in their \ac{CSR} JSON file. If a host is not mentioned in the resulting certificate, requests from the corresponding host are rejected.
\autoref{lst:background.ca-csr} shows such a configuration with accepted host names in the form of a \ac{CSR}.

\begin{lstlisting}[label=lst:background.ca-csr, caption={Example of meta data in form of \ac{CSR} configuration. \enquote{CN} is the certificate name. \enquote{hosts} describes the accepted hostnames, \enquote{key} describes information about the cryptography algorithm, \enquote{names} contains meta data of the organization}]
{
  "CN": "OpenTwin",
  "hosts": ["localhost", "127.0.0.1"],
  "key": {
    "algo": "rsa",
    "size": 4096},
  "names": [{
    "O": "Frankfurt University of Applied Sciences"
  }]
}
\end{lstlisting}



% TODO: Einführung Containerd CLI tools (crictl, nerdctl, ctr <preinstalled>)
% TODO: ContainerD kann kein Build auf Windows - buildkit daemon is required, buildkit: only linux is supported (https://github.com/moby/buildkit) buildkitd is only available for Linux currently. 
% TODO: Container file == Container file definition of file type .Containerfile
\section{Containers and Virtualization}
In general, there are two different options for isolating applications in cloud environments. These are Virtualization and Containerization. Both are briefly presented in this section.

\subsection{Virtualization}
Virtualization (or \acp{VM}) allows the software simulation of physical hardware to an \acp{OS}. The real hardware is faked to the \ac{OS} kernel and the \ac{VM} can, under optimal conditions, not distinguish between whether it is running on real hardware or if it runs in a simulation. Because \acp{VM} just run as a software on a physical machine (the so called \enquote{host computer}), it provides the possibility for operating multiple computers on one physical machine.
The fundamental architecture of the virtualization technology is shown in \autoref{fig:background.virtualization}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.65\textwidth]{Figures/virtualization.pdf}
	\caption{Brief presentation of the virtualization technology\cite{RamosApolinario.2021, Warrier.20201120}. Multiple \acp{OS} run on the same physical machine simultaneously. The hardware is mocked by the hypervisor layer.}
	\label{fig:background.virtualization}
\end{figure}

Besides isolating the \ac{OS} kernel and all of its processes, the network layer also has to be isolated. This is usually achieved by three  different approaches:
\begin{itemize}
\item \textbf{Network address translation} One approach is to convert the network packets between the \ac{VM} and the host computer based on \ac{NAT}. This means, the host computer provides a network interface which is connected to the \ac{VM}. Incoming and outgoing traffic to the \ac{VM} is translated using the additional virtual network interface. % TODO: Beleg
\item \textbf{Bridged network} In this approach the traffic between \ac{VM} and host computer is "bridged". This means, the \ac{VM} gets its own \ac{IP} address assigned and is seen and acts as its own member.
\item \textbf{Host network} The host network approach hides the \ac{VM} from the outer network and only allows communication between the \ac{VM} and the host machine.
\end{itemize}


Microsoft offers with Hyper-V its own virtualization software since Windows 8\cite{Microsoft.2013}.


\subsection{Container}
As shown in \autoref{fig:background.container}, Container have a more lightweight concept of isolation compared to virtualization. Instead of providing an isolation layer for both, the \ac{OS} kernel and the running processes, only the processes are isolated (\enquote{process isolation}). Compared to virtualization, this increases performance of the isolated processes and reduces the startup time.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{Figures/containerization.pdf}
	\caption{Brief presentation of the containerization technology\cite{RamosApolinario.2021, Warrier.20201120}. Each isolated process runs inside a container, the \ac{OS} kernel is shared.}
	\label{fig:background.container}
\end{figure}

Containers share the \ac{OS} kernel with the host system.  Thus, \ac{OS} kernel and processes running inside the container have to match.
However, this does allow libraries to be shared within containers where necessary\cite{Warrier.20201120}.
The process isolation is performed by encapsulating the file system, the users, the kernel processes and the network interfaces of the host system towards the container. Each container receives its own set of those encapsulated core objects. For the isolation of the network the same strategies as for virtualization apply.

Because of their lightweight nature, containers usually only encapsulate a single application process. For encapsulating an application, one has to build a \enquote{container image}.  For the description of an image, the Containerfile format\footnote{Containerfile: https://www.mankier.com/5/Containerfile} is mostly used. The preparation of an image as \enquote{infrastructure-as-code} allows to build a reproducible environment on different machines. An example of a Containerfile is given in \autoref{lst:background.containerfile}.

\begin{lstlisting}[label=lst:background.containerfile, caption={Example of a container file. A file (file.txt) is copied to a Windows Server container (to C:\textbackslash out.txt), and this file is printed during the container run using the command.}, language=docker]
FROM mcr.microsoft.com/windows/server:ltsc2022
COPY file.txt C:\out.txt
CMD type C:\out.txt
\end{lstlisting}

Container images can derive from other images that can derive from images again, and so on. Thus, an image definition consist of a general part as baseline (the \enquote{base image}) and an application specific part. On top of this chain is an image for containerizing the \ac{OS} processes. From which base image a container image derives is defined by the \tcode{FROM} statement (line~1).
The value after \tcode{FROM} defines the address to the base image, whereas the value \enquote{ltsc2022} is called \enquote{image tag} and usually used for defining a concrete version of the base image. In this case, this is \enquote{\ac{Windows} Server 2022}.

Other statements can be given, for example, for copying files into the container file system (line~2), running commands for preparing the image or defining meta data about the image. The statement \tcode{CMD} (line~3) defines the command that is automatically run and monitored, once the container image has started. If this command exits, the container is also automatically terminated.

If images are not available on a host system, they are \enquote{pulled} from a \enquote{container registry}. It is a server that hosts the images, and is available either public or private.


\section{Problem statement}
Even though the application is clearly based on a microservice architecture and is able to run on a distributed system, it is not designed for an automated cluster yet. 

Containerization of the system has never been tested and needs to be introduced. 
This is why one focus lies on the containerization of the application. Due to its complexity with \ac{mTLS} encrypted communication and its sophisticated behavior with spawning new processes on demand, the containerization on \ac{Windows} based system is challenging.
Moreover, virtualization on \ac{Windows} has shifted more and more towards containerization in recent years. Nevertheless, true process isolation is still a rather rarely used technology under Windows. This circumstance makes research and development of \ac{Windows} containers quite complex and therefore containerization of the application must be investigated first.

As prerequisite, the application needs to be adapted. Error handling and logging is not present in the current application. 
Even though the front end application does write logs, the microservices currently do not produce log files. Instead, only a few sub processes write the information on their standard output stream. In some cases, the error information given by exceptions is dropped.
Furthermore, proper exit codes in error cases are not returned. That is, if the application exits there is currently no way to detect if the process terminated normally or crashed as part of an error.
Therefore, for simplifying development of the container image, logging must be introduced and proper error handling should be optimized.

The second focus lies on the setup of the cluster with regards to \ac{Windows} nodes.
First, the cluster engine needs to be set up. Since clustering with \ac{Windows} containers is uncommon, preliminary studies where \ac{Windows} nodes are part of a cluster are rare. Some cluster designs should be probed to provide a qualitative statement about which configuration is feasible.
After adding the \ac{Windows} node to the cluster, the network interface has to be set up to provide connectivity between the services and nodes. 
The created containerized application must be provided to the cluster engine so that it can be rolled out. Thus, automatic deployment of the developed images in the cluster engine has to be investigated. 
The functional connectivity of the services has to be ensured by checking the connectivity with regards to the \ac{mTLS} encryption.

%As a proof of concept, the \ac{LSS} is containerized and a cluster is set up with one \ac{Windows} node.

\section{Limitations}
The time frame for performing the task is limited. This is why not all code changes are applied. This involves the adaption for automatic extension of services, but also implies the changes required to make the application more fault-tolerant. The changes that would be necessary, would be too extensive. Therefore, they are only made to the main processes.

This thesis aims to provide a proof of concept for shifting an existing application to the cluster. Since the previous research in the field of host-process container applications is rather limited, the focus is on the investigation of using \ac{Windows} nodes as part of the cluster.
This is why the application is not fully containerized. The main services are containerized and the cluster is set up to investigate the behavior in cluster environments. 
Rather than providing a complete step-by-step guide, it highlights the challenges of developing deployment automation for \ac{Windows}.
